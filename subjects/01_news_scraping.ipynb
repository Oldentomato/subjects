{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.daum.net/economy'\n",
    "\n",
    "def get_news(url, showDebug=True):\n",
    "    req_header = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'\n",
    "    }\n",
    "\n",
    "    res = requests.get(url=url, headers=req_header)\n",
    "\n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.content.decode('utf-8', 'replace'), 'html.parser') #한글 깨짐 방지\n",
    "        # CSS 선택자\n",
    "        news = soup.select(\"ul.list_newsheadline2 a[href*='v.daum.net/v']\")\n",
    "        if showDebug:\n",
    "            print(url)\n",
    "            print(type(res))\n",
    "            print(res.status_code)\n",
    "            print(type(news), len(news))\n",
    "        for value in news:\n",
    "            print(value.attrs[\"href\"])\n",
    "            print(value.text.strip())\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR CODE: {res.status_code}\")\n",
    "\n",
    "get_news(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_news(section):\n",
    "    section_dict = {'기후/환경':'climate','사회':'society','경제':'economy','정치':'politics',\n",
    "                    '국재':'world','문화':'culture','생활':'life','IT/과학':'tech','인물':'people'}\n",
    "\n",
    "    section_eng = section_dict[section]\n",
    "\n",
    "    url = f\"https://news.daum.net/{section_eng}\"\n",
    "    print(f\"===> {url} {section_eng} 뉴스 <===\")\n",
    "    get_news(url, showDebug=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_news('경제')\n",
    "print_news('사회')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://news.nate.com/recent?mid={0}\"\n",
    "sections = {\n",
    "    \"최신\": \"n0100\",\n",
    "    \"정치\": \"n0101\",\n",
    "    \"경제\": \"n0102\",\n",
    "    \"사회\": \"n0103\",\n",
    "    \"세계\": \"n0104\",\n",
    "    \"IT/과학\": \"n0105\"\n",
    "}\n",
    "\n",
    "\n",
    "def getNateNews(sectionName):\n",
    "    req_header = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'\n",
    "    }\n",
    "\n",
    "    res = requests.get(url=url.format(sections[sectionName]), headers=req_header)\n",
    "\n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.text, 'html.parser') #한글 깨짐 방지\n",
    "        # CSS 선택자\n",
    "        news = soup.select(\".postSubjectContent a[href*='//news.nate.com/view']\")\n",
    "        for value in news:\n",
    "            \n",
    "            hrefUrl = urljoin(base=url, url=value.attrs.get(\"href\"), allow_fragments=True)\n",
    "            if iamgeUrl := value.find(\"img\"):\n",
    "                imageUrl = urljoin(base=url, url=iamgeUrl.attrs.get(\"src\"), allow_fragments=True)\n",
    "                display(Image(url=imageUrl))\n",
    "            print(value.find(\"h2\").text)\n",
    "            print(hrefUrl)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR CODE: {res.status_code}\")\n",
    "\n",
    "getNateNews(\"정치\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def download_one_episode(title,no,url):\n",
    "    if not os.path.exists(dirPath := os.path.join(\"img\", title, str(no))):\n",
    "        os.makedirs(dirPath)\n",
    "    else:\n",
    "        req_header = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'\n",
    "        }\n",
    "\n",
    "        res = requests.get(url=url, headers=req_header)\n",
    "\n",
    "        if res.ok:\n",
    "            soup = BeautifulSoup(res.text, 'html.parser') \n",
    "            # CSS 선택자\n",
    "            contents = [data.get(\"src\") for data in soup.select(\".wt_viewer img\")]\n",
    "            for i,value in enumerate(contents):\n",
    "                imgRes = requests.get(value, headers=req_header)\n",
    "                if imgRes.ok:\n",
    "                    with open(os.path.join(dirPath,str(i))+\".jpg\", 'wb') as file:\n",
    "                        img_data = imgRes.content\n",
    "                        file.write(img_data)\n",
    "                else:\n",
    "                    print(f'Error Code = {imgRes.status_code} for {value}')\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f\"ERROR CODE: {res.status_code}\")\n",
    "\n",
    "download_one_episode('낢이사는이야기',48,'https://comic.naver.com/webtoon/detail?titleId=833255&no=49&week=tue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 3-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True, verbose=True)\n",
    "\n",
    "def getApiKey(apiName):\n",
    "    try:\n",
    "        key = os.getenv(apiName)\n",
    "    except:\n",
    "        raise Exception(\"No Api Key!\")\n",
    "    \n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     title author  discount publisher   pubdate\n",
      "0      파이썬    천인국     12000    인피니티북스  20170830\n",
      "1  파이썬 플러스    최희식     23750    인피니티북스  20240731\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def FormBookOutput(title,datas):\n",
    "    print(f\"=== {title} ===\")\n",
    "    for data in datas:\n",
    "        print(f\"\"\"\n",
    "    {data.get(\"title\")}\n",
    "    저자: {data.get(\"author\")}\n",
    "    출판사: {data.get(\"publisher\")}\n",
    "    출판일: {datetime.strptime(data.get(\"pubdate\"), \"%Y%m%d\").strftime(\"%Y-%m-%d\")}\n",
    "    가격: {data.get(\"discount\")}\n",
    "    설명: {des[:101]+\"...\" if len(des := data.get(\"description\"))> 100 else des}\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "def search_books(query):\n",
    "    url = 'https://openapi.naver.com/v1/search/book.json'\n",
    "    client_id = getApiKey(\"NAVER_CLIENT_KEY\")\n",
    "    client_secret = getApiKey(\"NAVER_SECRET_KEY\")\n",
    "\n",
    "\n",
    "    req_header = {\n",
    "        \"X-Naver-Client-Id\": client_id,\n",
    "        \"X-Naver-Client-Secret\": client_secret\n",
    "    }\n",
    "    payload = {\n",
    "        'query':  query, #'파이썬',\n",
    "        'display': 30,\n",
    "        'sort': 'sim'\n",
    "    }\n",
    "\n",
    "    res = requests.get(url, params=payload, headers=req_header)\n",
    "    return res.json()[\"items\"]\n",
    "\n",
    "resultList = search_books(\"파이썬\")\n",
    "\n",
    "# 1. 질문 :  검색어로  찾은  책 목록 출력하기\n",
    "# FormBookOutput(\"도서 목록\", resultList)\n",
    "# 2. 질문 :  검색어로  찾은  책 목록 중에서 가격이 2만원 이상인 책만 출력하기\n",
    "# FormBookOutput(\"가격이 20,000원 이상인 도서 목록\", list(filter(lambda x:int(x.get(\"discount\"))>=20000, resultList)))\n",
    "# 3. 질문 :  검색어로  찾은  책 목록 중에서 출판사가 인피니티북스인 책만 출력하기\n",
    "# FormBookOutput(\"인피니티북스 출판 도서 목록\", list(filter(lambda x:x.get(\"publisher\")==\"인피니티북스\", resultList)))\n",
    "\n",
    "# 4. 질문 :  검색어로  찾은  책 목록을 json 파일로 저장하기\n",
    "with open(\"./data/books.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultList, f, ensure_ascii=False, indent=2)\n",
    "# 2. books.json 파일을 Pandas DataFrame로 저장하기\n",
    "df = pd.read_json(\"./data/books.json\")\n",
    "\n",
    "# 3. 질문 :  검색어로  찾은  책 목록 출력하기\n",
    "print(df)\n",
    "\n",
    "# 4. 질문 :  검색어로  찾은  책 목록 중에서 가격이 2만원 이상인 책만 출력하기\n",
    "print(df[df['discount'] >= 20000][[\"title\",\"author\", \"discount\", \"publisher\", \"pubdate\"]].sort_values(by=\"discount\", ascending=False, axis=0).reset_index(drop=True))\n",
    "\n",
    "# 6. 질문 :  검색어로  찾은  책 목록 중에서 출판사가 인피니티북스인 책만 출력하기\n",
    "print(df[df['publisher'] == \"인피니티북스\"][[\"title\",\"author\", \"discount\", \"publisher\", \"pubdate\"]].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormShopOutput(title,datas): # f\"{...:,}\" => 숫자에 천 단위마다 ,를 넣으라는 뜻\n",
    "    print(f\"=== {title} ===\")\n",
    "    for data in datas:\n",
    "        print(f\"\"\"\n",
    "    {data.get(\"title\")}\n",
    "    최저가: {int(data.get(\"lprice\")):,}원  \n",
    "    브랜드: {data.get(\"brand\")}\n",
    "    쇼핑몰: {data.get(\"mallName\")}\n",
    "    링크: {data.get(\"link\")}\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "def search_shops(query):\n",
    "    url = 'https://openapi.naver.com/v1/search/shop.json'\n",
    "    client_id = getApiKey(\"NAVER_CLIENT_KEY\")\n",
    "    client_secret = getApiKey(\"NAVER_SECRET_KEY\")\n",
    "\n",
    "\n",
    "    req_header = {\n",
    "        \"X-Naver-Client-Id\": client_id,\n",
    "        \"X-Naver-Client-Secret\": client_secret\n",
    "    }\n",
    "    payload = {\n",
    "        'query':  query, #'파이썬',\n",
    "        'display': 30,\n",
    "        'sort': 'sim'\n",
    "    }\n",
    "\n",
    "    res = requests.get(url, params=payload, headers=req_header)\n",
    "    return res.json()[\"items\"]\n",
    "\n",
    "\n",
    "resultList = search_shops(\"가디건\")\n",
    "\n",
    "# 2. shops.json 파일을 Pandas DataFrame로 저장하기\n",
    "with open(\"./data/shops.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultList, f, ensure_ascii=False, indent=2)\n",
    "df = pd.read_json(\"./data/shops.json\")\n",
    "\n",
    "# 3. 질문 :  검색어로  찾은  Shop의 상품  목록 출력하기\n",
    "# FormShopOutput(\"쇼핑 검색 결과\", resultList)\n",
    "\n",
    "# 2. 질문 :  검색어로  찾은  Shop의 상품  목록 중에서 가격이 50,000원 이하인 상품만 출력하기\n",
    "# FormShopOutput(\"50,000원 이하 상품\", list(filter(lambda x:int(x.get(\"lprice\")) <= 50000, resultList)))\n",
    "\n",
    "# 4. 질문 :  검색어로  찾은  Shop의 상품  목록 중에서 특정 쇼핑몰 상품만 출력하기\n",
    "# FormShopOutput(\"네이버 상품\", list(filter(lambda x:x.get(\"mallName\") == \"네이버\", resultList)))\n",
    "\n",
    "\n",
    "# 3. 질문 :  검색어로  찾은  Shop의 상품  목록 출력하기\n",
    "print(df)\n",
    "\n",
    "# 4. 질문 :  검색어로  찾은  Shop의 상품  목록 중에서 가격이 50,000원 이하인 상품만 출력하기\n",
    "print(df[df['lprice'] <= 50000][[\"brand\",\"lprice\", \"mallName\", \"link\"]].sort_values(by=\"lprice\", axis=0).reset_index(drop=True))\n",
    "\n",
    "# 4. 질문 :  검색어로  찾은  Shop의 상품  목록 중에서 특정 쇼핑몰 상품만 출력하기\n",
    "print(df.loc[:,'lprice':'brand'].sort_values(by=\"lprice\", axis=0).reset_index(drop=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
